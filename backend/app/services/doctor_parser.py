import asyncio
from pyppeteer import launch
from bs4 import BeautifulSoup
import logging
from typing import List, Dict, Optional, Any
import json
import random
import re
import uuid
from datetime import datetime
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select
from ..models import DoctorProfile, ParsingTask
from ..config import settings

logger = logging.getLogger(__name__)

class DoctorParser:
    def __init__(self):
        self.proxy_list = []
        self.browser = None
        self.current_proxy_index = 0
        self.current_proxy_auth = None  # –•—Ä–∞–Ω–∏–º –¥–∞–Ω–Ω—ã–µ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏
        self.logger = logger  # –î–æ–±–∞–≤–ª—è–µ–º –ª–æ–≥–≥–µ—Ä –∫–∞–∫ –∞—Ç—Ä–∏–±—É—Ç –∫–ª–∞—Å—Å–∞

        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∏–∑ config
        self.max_retries = getattr(settings, 'PARSER_MAX_RETRIES', 10)
        self.request_timeout = getattr(settings, 'PARSER_REQUEST_TIMEOUT', 30) * 1000
        self.executable_path = getattr(settings, 'PUPPETEER_EXECUTABLE_PATH', None)
        self.headless = getattr(settings, 'PUPPETEER_HEADLESS', True)

        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è –±–æ—Ä—å–±—ã —Å –∫–∞–ø—á–µ–π
        self.captcha_max_retries = 20
        self.captcha_delay = random.uniform(3, 7)

    def _normalize_proxy_for_chromium(self, proxy_string: str) -> Dict:
        """–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ–∫—Å–∏ –¥–ª—è Chromium —Å —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ–º –¥–∞–Ω–Ω—ã—Ö –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏"""
        proxy_string = proxy_string.strip()

        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤ –ø—Ä–æ–∫—Å–∏
        patterns = [
            r'^([^:]+):([^@]+)@([^:]+):(\d+)$',  # user:pass@host:port
            r'^([^:]+):(\d+)$',  # host:port
            r'^(\d+\.\d+\.\d+\.\d+):(\d+)$'  # ip:port
        ]

        for i, pattern in enumerate(patterns):
            match = re.match(pattern, proxy_string)
            if match:
                if i == 0:  # user:pass@host:port
                    user, password, host, port = match.groups()
                    return {
                        'server': f"{host}:{port}",
                        'username': user,
                        'password': password,
                        'has_auth': True
                    }
                else:  # host:port –∏–ª–∏ ip:port
                    if i == 1:
                        host, port = match.groups()
                    else:
                        host, port = match.groups()
                    return {
                        'server': f"{host}:{port}",
                        'username': None,
                        'password': None,
                        'has_auth': False
                    }

        logger.warning(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –ø—Ä–æ–∫—Å–∏: {proxy_string}")
        return {
            'server': proxy_string,
            'username': None,
            'password': None,
            'has_auth': False
        }

    def set_proxy_list(self, proxy_strings: List[str]):
        """–£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å —Å–ø–∏—Å–æ–∫ –ø—Ä–æ–∫—Å–∏ —Å –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–µ–π –¥–ª—è Chromium"""
        self.proxy_list = []
        for proxy in proxy_strings:
            if proxy.strip():
                normalized = self._normalize_proxy_for_chromium(proxy.strip())
                self.proxy_list.append(normalized)
                auth_info = f" (—Å –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–µ–π {normalized['username']})" if normalized['has_auth'] else " (–±–µ–∑ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏)"
                logger.info(f"–î–æ–±–∞–≤–ª–µ–Ω –ø—Ä–æ–∫—Å–∏: {normalized['server']}{auth_info}")

        logger.info(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(self.proxy_list)} –ø—Ä–æ–∫—Å–∏ —Å–µ—Ä–≤–µ—Ä–æ–≤")

        # –ü–µ—Ä–µ–º–µ—à–∏–≤–∞–µ–º —Å–ø–∏—Å–æ–∫ –¥–ª—è —Å–ª—É—á–∞–π–Ω–æ–≥–æ –ø–æ—Ä—è–¥–∫–∞
        random.shuffle(self.proxy_list)

    def get_next_proxy(self) -> Optional[Dict]:
        """–ü–æ–ª—É—á–∏—Ç—å —Å–ª–µ–¥—É—é—â–∏–π –ø—Ä–æ–∫—Å–∏ –∏–∑ —Å–ø–∏—Å–∫–∞ (–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û)"""
        if not self.proxy_list:
            raise Exception("–ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –ø—Ä–æ–∫—Å–∏! –ü–∞—Ä—Å–∏–Ω–≥ –Ω–µ–≤–æ–∑–º–æ–∂–µ–Ω –±–µ–∑ –ø—Ä–æ–∫—Å–∏.")

        proxy = self.proxy_list[self.current_proxy_index]
        self.current_proxy_index = (self.current_proxy_index + 1) % len(self.proxy_list)
        return proxy

    async def init_browser(self, proxy_data: Dict) -> bool:
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±—Ä–∞—É–∑–µ—Ä–∞ –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û —Å –ø—Ä–æ–∫—Å–∏"""
        if not proxy_data:
            raise Exception("–ü—Ä–æ–∫—Å–∏ –æ–±—è–∑–∞—Ç–µ–ª–µ–Ω –¥–ª—è —Ä–∞–±–æ—Ç—ã –ø–∞—Ä—Å–µ—Ä–∞!")

        try:
            launch_options = {
                'headless': self.headless,
                'args': [
                    '--no-sandbox',
                    '--disable-setuid-sandbox',
                    '--disable-dev-shm-usage',
                    '--disable-gpu',
                    '--disable-web-security',
                    '--disable-features=VizDisplayCompositor',
                    '--disable-blink-features=AutomationControlled',
                    '--no-first-run',
                    '--no-default-browser-check',
                    '--disable-background-timer-throttling',
                    '--disable-backgrounding-occluded-windows',
                    '--disable-renderer-backgrounding',
                    '--disable-extensions',
                    '--disable-plugins',
                    '--disable-images',
                    f'--proxy-server={proxy_data["server"]}',  # –¢–æ–ª—å–∫–æ —Å–µ—Ä–≤–µ—Ä –±–µ–∑ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏
                ],
                'defaultViewport': {'width': 1366, 'height': 768},
                'ignoreHTTPSErrors': True,
                'timeout': self.request_timeout
            }

            # –î–æ–±–∞–≤–ª—è–µ–º executablePath —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –æ–Ω —É–∫–∞–∑–∞–Ω
            if self.executable_path:
                launch_options['executablePath'] = self.executable_path

            logger.info(f"–ó–∞–ø—É—Å–∫ –±—Ä–∞—É–∑–µ—Ä–∞ —Å –ø—Ä–æ–∫—Å–∏: {proxy_data['server']}")
            if proxy_data['has_auth']:
                logger.info(f"–ë—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∞ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è: {proxy_data['username']}")

            self.browser = await launch(launch_options)

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏ –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ page.authenticate()
            self.current_proxy_auth = proxy_data if proxy_data['has_auth'] else None

            return True

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –±—Ä–∞—É–∑–µ—Ä–∞ —Å –ø—Ä–æ–∫—Å–∏ {proxy_data['server']}: {e}")
            return False

    async def create_authenticated_page(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Å –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–µ–π –ø—Ä–æ–∫—Å–∏"""
        page = await self.browser.newPage()

        # –ï—Å–ª–∏ –µ—Å—Ç—å –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è –ø—Ä–æ–∫—Å–∏, —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –µ—ë
        if self.current_proxy_auth and self.current_proxy_auth['has_auth']:
            try:
                await page.authenticate({
                    'username': self.current_proxy_auth['username'],
                    'password': self.current_proxy_auth['password']
                })
                logger.info(f"‚úÖ –ê–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è –ø—Ä–æ–∫—Å–∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {self.current_proxy_auth['username']}")
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ —É—Å—Ç–∞–Ω–æ–≤–∫–∏ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏ –ø—Ä–æ–∫—Å–∏: {e}")

        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Å–ª—É—á–∞–π–Ω—ã–π User-Agent
        await page.setUserAgent(self._get_random_user_agent())

        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏
        await page.setExtraHTTPHeaders({
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'ru-RU,ru;q=0.8,en-US;q=0.5,en;q=0.3',
            'Accept-Encoding': 'gzip, deflate',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
        })

        return page

    async def close_browser(self):
        """–ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –∑–∞–∫—Ä—ã—Ç–∏–µ –±—Ä–∞—É–∑–µ—Ä–∞"""
        if self.browser:
            try:
                # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –∏ –∑–∞–∫—Ä—ã–≤–∞–µ–º –∏—Ö
                pages = await self.browser.pages()
                for page in pages:
                    try:
                        await page.close()
                    except:
                        pass

                # –ó–∞–∫—Ä—ã–≤–∞–µ–º –±—Ä–∞—É–∑–µ—Ä
                await self.browser.close()

                # –î–∞–µ–º –≤—Ä–µ–º—è –Ω–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ –∑–∞–∫—Ä—ã—Ç–∏–µ –ø—Ä–æ—Ü–µ—Å—Å–∞
                await asyncio.sleep(0.5)

            except Exception as e:
                logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–∫—Ä—ã—Ç–∏–∏ –±—Ä–∞—É–∑–µ—Ä–∞: {e}")
            finally:
                self.browser = None
                self.current_proxy_auth = None

    async def check_and_handle_captcha(self, page, url: str, current_proxy_data: Dict) -> tuple:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–ø—á–∏ —Å –ø–µ—Ä–µ–±–æ—Ä–æ–º –ø—Ä–æ–∫—Å–∏"""
        captcha_indicators = [
            '#checkbox-captcha-form',
            '.captcha',
            '[class*="captcha"]',
            '[id*="captcha"]',
            'form[action*="captcha"]',
            '.verify',
            '.verification',
            '.challenge',
            '.SmartCaptcha',
            '.YaCaptcha'
        ]

        attempt = 0
        while attempt < self.captcha_max_retries:
            try:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–∞–ø—á–∏
                captcha_found = False
                for selector in captcha_indicators:
                    captcha_element = await page.querySelector(selector)
                    if captcha_element:
                        captcha_found = True
                        logger.warning(f"üö´ –ö–∞–ø—á–∞ –Ω–∞–π–¥–µ–Ω–∞ ({selector}) –Ω–∞ {url} —Å –ø—Ä–æ–∫—Å–∏ {current_proxy_data['server']}")
                        break

                if not captcha_found:
                    logger.info(f"‚úÖ –ö–∞–ø—á–∏ –Ω–µ—Ç, –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –ø–∞—Ä—Å–∏–Ω–≥")
                    return True, page

                # –ï—Å–ª–∏ –∫–∞–ø—á–∞ –Ω–∞–π–¥–µ–Ω–∞ - –º–µ–Ω—è–µ–º –ø—Ä–æ–∫—Å–∏
                attempt += 1
                logger.info(f"üîÑ –ü–æ–ø—ã—Ç–∫–∞ {attempt}/{self.captcha_max_retries}: –°–º–µ–Ω–∞ –ø—Ä–æ–∫—Å–∏ –¥–ª—è –æ–±—Ö–æ–¥–∞ –∫–∞–ø—á–∏")

                # –ó–∞–∫—Ä—ã–≤–∞–µ–º —Ç–µ–∫—É—â–∏–π –±—Ä–∞—É–∑–µ—Ä
                await self.close_browser()

                # –ë–µ—Ä–µ–º —Å–ª–µ–¥—É—é—â–∏–π –ø—Ä–æ–∫—Å–∏
                new_proxy_data = self.get_next_proxy()
                logger.info(f"üîÄ –ü–µ—Ä–µ–∫–ª—é—á–∞–µ–º—Å—è –Ω–∞ –ø—Ä–æ–∫—Å–∏: {new_proxy_data['server']}")

                # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –±—Ä–∞—É–∑–µ—Ä —Å –Ω–æ–≤—ã–º –ø—Ä–æ–∫—Å–∏
                if not await self.init_browser(new_proxy_data):
                    logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–ø—É—Å—Ç–∏—Ç—å –±—Ä–∞—É–∑–µ—Ä —Å –ø—Ä–æ–∫—Å–∏ {new_proxy_data['server']}")
                    continue

                # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É —Å –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–µ–π
                page = await self.create_authenticated_page()

                # –ó–∞–¥–µ—Ä–∂–∫–∞ –ø–µ—Ä–µ–¥ –ø–æ–≤—Ç–æ—Ä–Ω—ã–º –ø–µ—Ä–µ—Ö–æ–¥–æ–º
                await asyncio.sleep(random.uniform(3, 8))

                # –ü–µ—Ä–µ—Ö–æ–¥–∏–º –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É —Å –Ω–æ–≤—ã–º –ø—Ä–æ–∫—Å–∏
                logger.info(f"üåê –ü–æ–≤—Ç–æ—Ä–Ω—ã–π –ø–µ—Ä–µ—Ö–æ–¥ –Ω–∞ {url} —Å –Ω–æ–≤—ã–º –ø—Ä–æ–∫—Å–∏ {new_proxy_data['server']}")
                await page.goto(url, {
                    'waitUntil': 'networkidle2',
                    'timeout': self.request_timeout
                })

                # –ñ–¥–µ–º –∑–∞–≥—Ä—É–∑–∫–∏
                await asyncio.sleep(random.uniform(2, 5))

                # –û–±–Ω–æ–≤–ª—è–µ–º —Ç–µ–∫—É—â–∏–π –ø—Ä–æ–∫—Å–∏
                current_proxy_data = new_proxy_data

            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∫–∞–ø—á–∏: {e}")
                attempt += 1
                await asyncio.sleep(random.uniform(2, 5))

        logger.error(f"üíÄ –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±–æ–π—Ç–∏ –∫–∞–ø—á—É –ø–æ—Å–ª–µ {self.captcha_max_retries} –ø–æ–ø—ã—Ç–æ–∫ —Å —Ä–∞–∑–Ω—ã–º–∏ –ø—Ä–æ–∫—Å–∏")
        return False, page

    async def parse_doctor_page(self, url: str, max_retries: Optional[int] = None) -> Dict:
        """–ü–∞—Ä—Å–∏–Ω–≥ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –¢–û–õ–¨–ö–û —á–µ—Ä–µ–∑ –ø—Ä–æ–∫—Å–∏ —Å –∞–∫—Ç–∏–≤–Ω–æ–π –±–æ—Ä—å–±–æ–π —Å –∫–∞–ø—á–µ–π"""
        if not self.proxy_list:
            return {
                'profile_url': url,
                'error': '–ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –ø—Ä–æ–∫—Å–∏ –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞',
                'success': False
            }

        retries = max_retries or self.max_retries
        page = None

        for attempt in range(retries):
            # –í–°–ï–ì–î–ê –±–µ—Ä–µ–º –ø—Ä–æ–∫—Å–∏ (–Ω–∏–∫–æ–≥–¥–∞ –±–µ–∑ –Ω–µ–≥–æ)
            current_proxy_data = self.get_next_proxy()

            try:
                logger.info(f"üéØ –ü–æ–ø—ã—Ç–∫–∞ {attempt + 1}/{retries}: –ü–∞—Ä—Å–∏–Ω–≥ {url} —á–µ—Ä–µ–∑ –ø—Ä–æ–∫—Å–∏ {current_proxy_data['server']}")

                # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –±—Ä–∞—É–∑–µ—Ä –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û —Å –ø—Ä–æ–∫—Å–∏
                if not await self.init_browser(current_proxy_data):
                    logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–ø—É—Å—Ç–∏—Ç—å –±—Ä–∞—É–∑–µ—Ä —Å –ø—Ä–æ–∫—Å–∏ {current_proxy_data['server']}")
                    continue

                # –°–æ–∑–¥–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É —Å –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–µ–π
                page = await self.create_authenticated_page()

                # –ü–µ—Ä–µ—Ö–æ–¥–∏–º –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É
                logger.info(f"üåê –ü–µ—Ä–µ—Ö–æ–¥ –Ω–∞: {url} —á–µ—Ä–µ–∑ –ø—Ä–æ–∫—Å–∏ {current_proxy_data['server']}")
                await page.goto(url, {
                    'waitUntil': 'networkidle2',
                    'timeout': self.request_timeout
                })

                # –ñ–¥–µ–º –∑–∞–≥—Ä—É–∑–∫–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
                await asyncio.sleep(random.uniform(3, 6))

                # –ê–ö–¢–ò–í–ù–ê–Ø –ë–û–†–¨–ë–ê –° –ö–ê–ü–ß–ï–ô
                captcha_handled, page = await self.check_and_handle_captcha(page, url, current_proxy_data)
                if not captcha_handled:
                    logger.error(f"üíÄ –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±–æ–π—Ç–∏ –∫–∞–ø—á—É –¥–ª—è {url}")
                    await self.close_browser()
                    continue

                # –ü–∞—Ä—Å–∏–º –¥–∞–Ω–Ω—ã–µ —á–µ—Ä–µ–∑ page –æ–±—ä–µ–∫—Ç (–ù–ï HTML —Å—Ç—Ä–æ–∫—É!)
                parsed_data = await self._parse_html_content(page, url)

                # –ë–µ–∑–æ–ø–∞—Å–Ω–æ –∑–∞–∫—Ä—ã–≤–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É –∏ –±—Ä–∞—É–∑–µ—Ä
                try:
                    if page:
                        await page.close()
                except:
                    pass
                await self.close_browser()

                if parsed_data:
                    parsed_data['success'] = True
                    logger.info(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω: {url} —á–µ—Ä–µ–∑ –ø—Ä–æ–∫—Å–∏ {current_proxy_data['server']}")
                    return parsed_data
                else:
                    logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –¥–∞–Ω–Ω—ã–µ –∏–∑ {url}")
                    continue

            except Exception as e:
                error_msg = str(e)
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ {url} —Å –ø—Ä–æ–∫—Å–∏ {current_proxy_data['server']} (–ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}): {error_msg}")

                # –ë–µ–∑–æ–ø–∞—Å–Ω–æ –∑–∞–∫—Ä—ã–≤–∞–µ–º –±—Ä–∞—É–∑–µ—Ä –ø—Ä–∏ –æ—à–∏–±–∫–µ
                await self.close_browser()

                if attempt == retries - 1:
                    return {
                        'profile_url': url,
                        'error': f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –ø–æ—Å–ª–µ {retries} –ø–æ–ø—ã—Ç–æ–∫ —Å —Ä–∞–∑–Ω—ã–º–∏ –ø—Ä–æ–∫—Å–∏: {error_msg}",
                        'success': False
                    }

                # –ó–∞–¥–µ—Ä–∂–∫–∞ –ø–µ—Ä–µ–¥ —Å–ª–µ–¥—É—é—â–µ–π –ø–æ–ø—ã—Ç–∫–æ–π
                await asyncio.sleep(random.uniform(3, 8))

        return {
            'profile_url': url,
            'error': '–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ø—ã—Ç–æ–∫ –∏—Å—á–µ—Ä–ø–∞–Ω–æ',
            'success': False
        }

    async def _parse_html_content(self, page, url: str = None) -> Optional[Dict[str, Any]]:
        """–ü–∞—Ä—Å–∏–Ω–≥ HTML –∫–æ–Ω—Ç–µ–Ω—Ç–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –≤—Ä–∞—á–∞ —Å –Ø–Ω–¥–µ–∫—Å–∞"""
        try:
            # –û–∂–∏–¥–∞–µ–º –∑–∞–≥—Ä—É–∑–∫–∏ –æ—Å–Ω–æ–≤–Ω—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤
            try:
                await page.waitForSelector('.CardHeader-Title, .OrganicTitle-Link', timeout=10000)
            except:
                # –ï—Å–ª–∏ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã, –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –ø–∞—Ä—Å–∏–Ω–≥
                pass

            # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–º–µ–Ω–∏ –≤—Ä–∞—á–∞
            name = ""
            name_selectors = [
                '.CardHeader-Title',
                '.OrganicTitle-Link',
                '.DoctorCard-Name',
                'h1'
            ]

            for selector in name_selectors:
                try:
                    name_element = await page.querySelector(selector)
                    if name_element:
                        name = await page.evaluate('(element) => element.textContent', name_element)
                        name = name.strip() if name else ""
                        if name:
                            break
                except:
                    continue

            # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –∏ —Å—Ç–∞–∂–∞ –∏–∑ –æ–ø–∏—Å–∞–Ω–∏—è
            specialization = ""
            experience = ""

            description_selectors = [
                '.Description-Paragraph',
                '.DoctorCard-Specialization',
                '.OrganicText',
                '.Snippet'
            ]

            for selector in description_selectors:
                try:
                    elements = await page.querySelectorAll(selector)
                    for element in elements:
                        text = await page.evaluate('(element) => element.textContent', element)
                        if text:
                            text = text.strip()

                            # –ü–æ–∏—Å–∫ —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ (–æ–±—ã—á–Ω–æ –ø–µ—Ä–≤–∞—è —Å—Ç—Ä–æ–∫–∞ –æ–ø–∏—Å–∞–Ω–∏—è)
                            if not specialization and any(word in text.lower() for word in
                                ['–≤—Ä–∞—á', '–¥–æ–∫—Ç–æ—Ä', '—Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç', '—Ç–µ—Ä–∞–ø–µ–≤—Ç', '—Ö–∏—Ä—É—Ä–≥', '–∫–∞—Ä–¥–∏–æ–ª–æ–≥',
                                 '–Ω–µ–≤—Ä–æ–ª–æ–≥', '–æ—Ñ—Ç–∞–ª—å–º–æ–ª–æ–≥', '–ø–µ–¥–∏–∞—Ç—Ä', '–≥–∏–Ω–µ–∫–æ–ª–æ–≥']):
                                specialization = text

                            # –ü–æ–∏—Å–∫ —Å—Ç–∞–∂–∞ —Ä–∞–±–æ—Ç—ã
                            if '—Å—Ç–∞–∂' in text.lower() or '–æ–ø—ã—Ç' in text.lower():
                                experience = text
                except:
                    continue

            # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –∫–ª–∏–Ω–∏–∫–∞—Ö/—Ä–∞–±–æ—á–∏—Ö –º–µ—Å—Ç–∞—Ö
            workplace = ""
            clinic_selectors = [
                '.UniSearchMedicineClinics',
                '.DoctorCard-Clinic',
                '.OrganicCard-Clinic',
                '.Clinic-Name'
            ]

            clinics = []
            for selector in clinic_selectors:
                try:
                    elements = await page.querySelectorAll(selector)
                    for element in elements:
                        clinic_text = await page.evaluate('(element) => element.textContent', element)
                        if clinic_text:
                            clinic_text = clinic_text.strip()
                            if clinic_text and clinic_text not in clinics:
                                clinics.append(clinic_text)
                except:
                    continue

            workplace = "; ".join(clinics) if clinics else ""

            # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ä–µ–π—Ç–∏–Ω–≥–∞
            rating = ""
            rating_selectors = [
                '.ReviewAspectPercentageShort',
                '.Rating-Value',
                '.Stars-Value',
                '.DoctorCard-Rating'
            ]

            for selector in rating_selectors:
                try:
                    element = await page.querySelector(selector)
                    if element:
                        rating_text = await page.evaluate('(element) => element.textContent', element)
                        if rating_text:
                            rating = rating_text.strip()
                            # –ò–∑–≤–ª–µ–∫–∞–µ–º —á–∏—Å–ª–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ —Ä–µ–π—Ç–∏–Ω–≥–∞
                            rating_match = re.search(r'(\d+[.,]\d+|\d+)', rating)
                            if rating_match:
                                rating = rating_match.group(1).replace(',', '.')
                                break
                except:
                    continue

            # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –æ—Ç–∑—ã–≤–æ–≤
            reviews_count = ""
            reviews_selectors = [
                '.Reviews-Count',
                '.ReviewsCount',
                '.DoctorCard-ReviewsCount'
            ]

            for selector in reviews_selectors:
                try:
                    element = await page.querySelector(selector)
                    if element:
                        reviews_text = await page.evaluate('(element) => element.textContent', element)
                        if reviews_text:
                            reviews_match = re.search(r'(\d+)', reviews_text)
                            if reviews_match:
                                reviews_count = reviews_match.group(1)
                                break
                except:
                    continue

            # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–ª–µ—Ñ–æ–Ω–æ–≤
            phone = ""
            phone_selectors = [
                '.UniSearchMedicinePhone',
                '.DoctorCard-Phone',
                '.Phone-Number',
                'a[href^="tel:"]'
            ]

            phones = []
            for selector in phone_selectors:
                try:
                    elements = await page.querySelectorAll(selector)
                    for element in elements:
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º href –¥–ª—è tel: —Å—Å—ã–ª–æ–∫
                        if selector == 'a[href^="tel:"]':
                            phone_href = await page.evaluate('(element) => element.href', element)
                            if phone_href:
                                phone_number = phone_href.replace('tel:', '').strip()
                                if phone_number and phone_number not in phones:
                                    phones.append(phone_number)
                        else:
                            phone_text = await page.evaluate('(element) => element.textContent', element)
                            if phone_text:
                                phone_text = phone_text.strip()
                                # –û—á–∏—â–∞–µ–º —Ç–µ–ª–µ—Ñ–æ–Ω –æ—Ç –ª–∏—à–Ω–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤, –æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ —Ü–∏—Ñ—Ä—ã, +, -, (, )
                                clean_phone = re.sub(r'[^\d+\-\(\)\s]', '', phone_text)
                                if clean_phone and len(clean_phone) >= 10 and clean_phone not in phones:
                                    phones.append(clean_phone)
                except:
                    continue

            phone = "; ".join(phones) if phones else ""

            # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∞–¥—Ä–µ—Å–æ–≤
            address = ""
            address_selectors = [
                '.OrganicCard-Address',
                '.DoctorCard-Address',
                '.Clinic-Address',
                '.Address-Text'
            ]

            addresses = []
            for selector in address_selectors:
                try:
                    elements = await page.querySelectorAll(selector)
                    for element in elements:
                        address_text = await page.evaluate('(element) => element.textContent', element)
                        if address_text:
                            address_text = address_text.strip()
                            if address_text and address_text not in addresses:
                                addresses.append(address_text)
                except:
                    continue

            address = "; ".join(addresses) if addresses else ""

            # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–æ)
            education = ""
            education_selectors = [
                '.DoctorCard-Education',
                '.Education-Text',
                '.Doctor-Education'
            ]

            for selector in education_selectors:
                try:
                    element = await page.querySelector(selector)
                    if element:
                        education = await page.evaluate('(element) => element.textContent', element)
                        education = education.strip() if education else ""
                        if education:
                            break
                except:
                    continue

            # –ü–æ–ª—É—á–∞–µ–º URL —Ç–µ–∫—É—â–µ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã
            profile_url = url if url else page.url

            # –§–æ—Ä–º–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            doctor_data = {
                'name': name,
                'specialization': specialization,
                'experience': experience,
                'education': education,
                'workplace': workplace,
                'rating': rating,
                'reviews_count': reviews_count,
                'phone': phone,
                'address': address,
                'profile_url': profile_url
            }

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –ø–æ–ª—É—á–∏–ª–∏ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –¥–∞–Ω–Ω—ã–µ
            if name or specialization:
                self.logger.info(f"–£—Å–ø–µ—à–Ω–æ –∏–∑–≤–ª–µ—á–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ –≤—Ä–∞—á–∞: {name}")
                return doctor_data
            else:
                self.logger.warning("–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –æ—Å–Ω–æ–≤–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –≤—Ä–∞—á–∞ (–∏–º—è –∏–ª–∏ —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—é)")
                return None

        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ HTML: {str(e)}")
            return None

    def _get_random_user_agent(self) -> str:
        """–ü–æ–ª—É—á–∏—Ç—å —Å–ª—É—á–∞–π–Ω—ã–π —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–π User-Agent"""
        user_agents = [
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:121.0) Gecko/20100101 Firefox/121.0',
            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:121.0) Gecko/20100101 Firefox/121.0',
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Edge/120.0.0.0',
        ]
        return random.choice(user_agents)

    async def parse_urls_batch(self, urls: List[str], db: AsyncSession, task_uuid: str,
                              batch_size: int = 1, delay_between_requests: float = 5.0):
        """–ü–∞–∫–µ—Ç–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –¢–û–õ–¨–ö–û —á–µ—Ä–µ–∑ –ø—Ä–æ–∫—Å–∏ —Å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–µ–π"""

        if not self.proxy_list:
            logger.error("‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: –ù–µ—Ç –ø—Ä–æ–∫—Å–∏! –ü–∞—Ä—Å–∏–Ω–≥ –Ω–µ–≤–æ–∑–º–æ–∂–µ–Ω.")
            return

        try:
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º task_uuid –≤ UUID –µ—Å–ª–∏ —ç—Ç–æ —Å—Ç—Ä–æ–∫–∞
            if isinstance(task_uuid, str):
                task_uuid = uuid.UUID(task_uuid)

            # –ü–æ–ª—É—á–∞–µ–º –∑–∞–¥–∞—á—É
            task_query = select(ParsingTask).where(ParsingTask.task_id == task_uuid)
            result = await db.execute(task_query)
            task = result.scalar_one_or_none()

            if not task:
                logger.error(f"–ó–∞–¥–∞—á–∞ —Å task_id {task_uuid} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
                return

            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –∑–∞–¥–∞—á–∏
            task.status = "running"
            await db.commit()
            await db.refresh(task)  # –û–±–Ω–æ–≤–ª—è–µ–º –æ–±—ä–µ–∫—Ç –∏–∑ –ë–î

            total_urls = len(urls)
            completed = 0
            successful = 0

            logger.info(f"üöÄ –ù–∞—á–∏–Ω–∞–µ–º –ø–∞—Ä—Å–∏–Ω–≥ {total_urls} URL —á–µ—Ä–µ–∑ {len(self.proxy_list)} –ø—Ä–æ–∫—Å–∏")

            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—ã–π URL –æ—Ç–¥–µ–ª—å–Ω–æ
            for i, url in enumerate(urls, 1):
                try:
                    logger.info(f"üìã –û–±—Ä–∞–±–æ—Ç–∫–∞ {i}/{total_urls}: {url}")

                    # –ü–∞—Ä—Å–∏–º —Å—Ç—Ä–∞–Ω–∏—Ü—É
                    result = await self.parse_doctor_page(url)

                    # –°–æ–∑–¥–∞–µ–º –∑–∞–ø–∏—Å—å –≤ –ë–î
                    doctor_profile = DoctorProfile(
                        task_id=task_uuid,
                        name=result.get('name', ''),
                        specialization=result.get('specialization', ''),
                        experience=result.get('experience', ''),
                        education=result.get('education', ''),
                        workplace=result.get('workplace', ''),
                        rating=result.get('rating', ''),
                        reviews_count=result.get('reviews_count', ''),
                        phone=result.get('phone', ''),
                        address=result.get('address', ''),
                        profile_url=result.get('profile_url', url),
                        parsing_date=datetime.utcnow()
                    )

                    db.add(doctor_profile)
                    completed += 1

                    if result.get('success', False):
                        successful += 1
                        logger.info(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω –≤—Ä–∞—á: {result.get('name', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')}")
                    else:
                        logger.warning(f"‚ö†Ô∏è –û–±—Ä–∞–±–æ—Ç–∞–Ω —Å –æ—à–∏–±–∫–æ–π: {result.get('error', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞')}")

                    # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –≤ –Ω–æ–≤–æ–π —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏
                    try:
                        # –ü–µ—Ä–µ–∑–∞–≥—Ä—É–∂–∞–µ–º –∑–∞–¥–∞—á—É –∏–∑ –ë–î
                        fresh_task_query = select(ParsingTask).where(ParsingTask.task_id == task_uuid)
                        fresh_result = await db.execute(fresh_task_query)
                        fresh_task = fresh_result.scalar_one_or_none()

                        if fresh_task:
                            fresh_task.processed_profiles = completed
                            await db.commit()
                            logger.info(f"üìä –ü—Ä–æ–≥—Ä–µ—Å—Å: {completed}/{total_urls} ({successful} —É—Å–ø–µ—à–Ω—ã—Ö)")
                        else:
                            logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –∑–∞–¥–∞—á—É –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞")

                    except Exception as progress_error:
                        logger.error(f"–û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞: {progress_error}")
                        await db.rollback()

                    # –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –≤—Ä–∞—á–∞–º–∏
                    if completed < total_urls:
                        delay = random.uniform(delay_between_requests, delay_between_requests + 3)
                        logger.info(f"‚è≥ –ó–∞–¥–µ—Ä–∂–∫–∞ {delay:.1f}—Å –ø–µ—Ä–µ–¥ —Å–ª–µ–¥—É—é—â–∏–º –≤—Ä–∞—á–æ–º")
                        await asyncio.sleep(delay)

                except Exception as e:
                    logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ {url}: {e}")

                    # –°–æ–∑–¥–∞–µ–º –∑–∞–ø–∏—Å—å —Å –æ—à–∏–±–∫–æ–π
                    try:
                        doctor_profile = DoctorProfile(
                            task_id=task_uuid,
                            name="–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞",
                            profile_url=url,
                            parsing_date=datetime.utcnow()
                        )

                        db.add(doctor_profile)
                        completed += 1
                        await db.commit()
                    except Exception as db_error:
                        logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ø—Ä–æ—Ñ–∏–ª—è —Å –æ—à–∏–±–∫–æ–π: {db_error}")
                        await db.rollback()

            # –ó–∞–≤–µ—Ä—à–∞–µ–º –∑–∞–¥–∞—á—É
            try:
                final_task_query = select(ParsingTask).where(ParsingTask.task_id == task_uuid)
                final_result = await db.execute(final_task_query)
                final_task = final_result.scalar_one_or_none()

                if final_task:
                    final_task.status = "completed"
                    final_task.completed_at = datetime.utcnow()
                    final_task.processed_profiles = completed
                    await db.commit()

                    logger.info(f"üéâ –ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω! –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {completed}/{total_urls}, –£—Å–ø–µ—à–Ω—ã—Ö: {successful}")
                else:
                    logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –∑–∞–¥–∞—á—É –¥–ª—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è")

            except Exception as final_error:
                logger.error(f"–û—à–∏–±–∫–∞ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –∑–∞–¥–∞—á–∏: {final_error}")
                await db.rollback()

        except Exception as e:
            logger.error(f"üíÄ –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞–∫–µ—Ç–Ω–æ–º –ø–∞—Ä—Å–∏–Ω–≥–µ: {e}")

            try:
                # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –Ω–∞ –æ—à–∏–±–∫—É
                error_task_query = select(ParsingTask).where(ParsingTask.task_id == task_uuid)
                error_result = await db.execute(error_task_query)
                error_task = error_result.scalar_one_or_none()

                if error_task:
                    error_task.status = "failed"
                    error_task.error_message = str(e)
                    error_task.completed_at = datetime.utcnow()
                    await db.commit()
            except Exception as error_update_error:
                logger.error(f"–û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Å—Ç–∞—Ç—É—Å–∞ –æ—à–∏–±–∫–∏: {error_update_error}")
                await db.rollback()

    async def save_profile_to_db(self, profile_data: dict, task_uuid: str, db: AsyncSession):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø—Ä–æ—Ñ–∏–ª—è —Å –ø—Ä–∏–≤—è–∑–∫–æ–π –∫ task_id"""
        try:
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º task_uuid –≤ UUID –µ—Å–ª–∏ —ç—Ç–æ —Å—Ç—Ä–æ–∫–∞
            if isinstance(task_uuid, str):
                task_uuid = uuid.UUID(task_uuid)

            doctor_profile = DoctorProfile(
                task_id=task_uuid,
                name=profile_data.get('name', ''),
                specialization=profile_data.get('specialization', ''),
                experience=profile_data.get('experience', ''),
                education=profile_data.get('education', ''),
                workplace=profile_data.get('workplace', ''),
                rating=profile_data.get('rating', ''),
                reviews_count=profile_data.get('reviews_count', ''),
                phone=profile_data.get('phone', ''),
                address=profile_data.get('address', ''),
                profile_url=profile_data.get('profile_url', ''),
                parsing_date=datetime.utcnow()
            )

            db.add(doctor_profile)
            await db.commit()
            return doctor_profile

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ø—Ä–æ—Ñ–∏–ª—è: {e}")
            await db.rollback()
            raise